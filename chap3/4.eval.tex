\section{Evaluation}\label{sec:eval}

We evaluated the Omni coarray compiler on the systems shown in \tab{specs}.

\begin{table}
 \begin{center}
  \caption{Specs of the compulters used for evaluation}\label{tab:specs}
  \begin{tabular}{l|p{0.4\textwidth}|p{0.4\textwidth}}
   \hline
   & HOKUSAI GreatWare (RIKEN RCCS)   & CCS, University of Tsukuba \\
   & Fujitsu PRIMEHPC FX100           & HA-PACS/TCA \\
   \hline
   \hline
   CPU
   & SPARK64\texttrademark XIfx, 1.975GHz, 1CPU per node, 4-SIMD $\times$ 32-core
   & E5-2680 v2 (Ivy Bridge), 10-core, 224GFlops, 2CPU per node \\
   \hline
   memory
   & 32GB per node, bandwidth 480GB/s per node
   & DDR3 SDRAM 128GB per node, 119.4GB/s   \\
   \hline
   interconnect
   & Tofu2, 12.5GB/s $\times$ 2
   & InfiniBand FDR, 7GB/s \\
   \hline
   compiler
   & Fujitsu Fortran Ver.\ 2.0.0 P-id:T01776-01
   & Intel Fortran 16.0.4 \\
   \hline
   MPI
   & Fujitu MPI Ver.\ 2.0.0 P-id:T01776-01 (OpenMPI base)
   & Intel MPI 5.1.3 \\
   \hline
   comm.\ layer
   & Tofu library
   & GASNet 1.24.2 built as IBV-conduit with Intel compilers \\
   \hline
  \end{tabular}
 \end{center}
\end{table}



%-----------------------------------------------------------------------------
\subsection{Fundamental Performance}
%-----------------------------------------------------------------------------

%===============
% 説明
%===============

Using EPCC Fortran Coarray micro-benchmark~\cite{EPCC}, we evaluated ping-pong performance 
of PUT and GET communications compared with MPI\_Send/Recv.
The codes are shortly shown in \tab{pingpong-code}.

%-- pingpong-code.pdf
\begin{table}[bht]
  \begin{center}
    \caption{pingpong-code.pdf}\label{tab:pingpong-code}
    % trimはleft bottom right topの順
    \mbox{\includegraphics[trim=24mm 211mm 24mm 16mm, scale=0.7,clip]{figs/pingpong-code-r2.pdf}}
    \begin{flushright}
      {\tt me} is the image index. {\tt id} is the MPI rank number.
    \end{flushright}
  \end{center}
\end{table}

%-- pingpong-fig.pdf
\begin{figure}[bht]
  \begin{center}
    \mbox{\includegraphics[trim=30mm 195mm 32mm 16mm, scale=0.75,clip]{figs/pingpong-fig-r2.pdf}}
    \caption{pingpong-fig.pdf}\label{fig:pingpong-fig}
  \end{center}
\end{figure}

Corresponding to the codes in \tab{pingpong-code}, \fig{pingpong-fig} shows how data and 
messages are echanged between two images or processes.
In coarray PUT (a) and GET (b), inter-image synchronization is necessary for each end of 
phases to make the passive image active and to make the active image passive.
While, in MPI message-passing (c) and (d), such synchronization is not necessary because
both processes are always active.
%
On the other hand, MPI message-passing has its own overhead that coarray PUT/GET
does not have. Because the eager protocol (c) does not use RDMA, the receiver
must copy the received data in the local buffer to the target. The larger the data,
the greater the overhead cost.
In the rendezvous protocol (d), negotiations including remote address notification
are required prior to the communication.
The overhead cost is not negligible when the data is small.


%===============
% 結果
%===============

\begin{figure}[p]
  \begin{center}
    % trimはleft bottom right topの順
    %\mbox{\includegraphics[trim=30mm 80mm 30mm 25mm, scale=0.8, clip]{graphs/8graphs-7.pdf}}
    \mbox{\includegraphics[trim=30mm 70mm 30mm 23mm, scale=0.78, clip]{graphs/8graphs-8.pdf}}
    \caption{Ping-pong performance on Fujitsu PRIMEHPC FX100 and HA-PACS/TCA}\label{fig:8graphs}
  \end{center}
\end{figure}

The result of the comparision between coarray PUT/GET and MPI message passing is shown in
\fig{8graphs}.
As the underlying communication libraries, 
FJ-RDMA and MPI-3 are used on FX100 and GASNet and MPI-3 are used on HA-PACS.
GET(a) and GET(b) are using the code without and with the optimization described in
\Sec{opt-get}, respectively.
Bandwidth is the communication data size per elapsed time, and
latency is half of the ping-pong elapsed time.
The difference between GET(a) and (b) is the compile-time optimization level of the 
coarray translator described in \Sec{opt-get}.

%===============
% 分かったこと
%===============

As the result, the following was found about coarray PUT/GET communication.

\begin{enumerate}

\item {\em Bandwidth.}
Coarray PUT and GET are slightly outperforms MPI rendezvous communication for large data 
on FJ-RDMA and MPI-3.
On FJ-RDMA/FX100 (a), the bandwidth of PUT and GET(b) are respectively 
+0.1\% to +18\% and -0.4\% to +9.3\% higher than MPI rendezbous in the 
rendezvous range of 32k through 32M bytes.
Also on MPI-3/HA-PACS, respectively +0.3\% to +0.8\% and 
+0.1\% to +1.3\% higher in the rendezvous range of 512k through 32M bytes.

It was confirmed from the runtime log that zero-copy communication was performed
both in PUT and GET(b) by selecting DMA scheme described in \Sec{opt-dma}.

However, on GASNet/HA-PACS (c), PUT and GET(b) has only about 60\% bandwidth for large data
than MPI rendezvous.
It is presumed that data copy was caused internally.

\item {\em Latency.}
On FJ-RDMA (a) and MPI-3 (b) and (d), PUT and GET(b) have larger (worse) latency than 
MPI eager communication, in the range of $\leq$16kB on FX100 and $\leq$256kB on HA-PACS.

Coarray on GASNet (c) behaves differently than other cases on (a), (b) and (d).
Though the latency is larger than the one of MPI for all data sizes, the difference
is smaller than the other cases. At data size 8B, the latency of PUT is 2.93$\mu$s
and 2.1 times larger than the one of MPI 
while 5.73$\mu$s and 3.7 times larger on the case of MPI-3 (d).

\item {\em Effect of GET optimization.}
For all ranges of all cases, GET(a) has smaller bandwidth and larger latency than GET(b).
On FJ-RDMA (a), the bandwidth is 1.41 to 1.85 times improved in the range of 32kB to 32MB
by changing the object code of GET(a) to (b).
We found GET(a) caused two extra memory copies; one is performing the array assignment 
by the Fortran library and the other is the copy from the communication buffer 
to the result variable of the array function {\tt xmpf\_coarray\_get\_generic}. 
The optimization described in \Sec{opt-get} has eliminated these two data copies.

\end{enumerate}

The issue is the large latency of coarray PUT/GET communication.
In the next subsection, it is discussed how it should be solved 
by the compiler and the programming.



%===========================================================
\subsection{Non-blocking communication}
%===========================================================

For latency hiding, asynchronous and non-blocking features can be expected 
on coarray PUT communication.
The principle is shown in \fig{nonblock-fig}.
%
\fig{nonblock-fig} (a) illustrates the half pattern of the ping-pong PUT communication.
Coarray one-sided communication is basically asynchronous unless 
synchronization is explicitly specified. Therefore, multiple communications
without synchronization between them, as shown in (b), is closer to actural applications.
In addition, it can be optimized using non-blocking communication as shown in (c).
Blocking and non-blocking communications can be switched with the runtime environment
variable in the current implementation of the Omni compiler.
In MPI message passing, non-blocking communication can be written with 
{\tt MPI\_Isend}, {\tt MPI\_Irecv} and {\tt MPI\_Wait}.

%-- nonblock-fig.pdf
\begin{figure}[tbh]
  \begin{center}
  % trimはleft bottom right topの順
    \mbox{\includegraphics[trim=43mm 144mm 43mm 3mm, scale=0.6,clip]{figs/nonblock-fig-r2.pdf}}
    \caption{nonblock-fig.pdf}\label{fig:nonblock-fig}
  \end{center}
\end{figure}


\fig{8var-pingpong} compares blocking/non-blocking coarray PUT and 
MPI message passing communications.
Two original graphs are the same as the ones of \fig{8graphs} (a).
Other four graphs display the result of 8-variable ping-pong program, 
which repeats the ping phase sending eight individual variables 
from one to the other in order and the pong phase doing similarly 
in the opposite direction.
Each blocksize indicates the size of variables and latency includes the
time for eight variables.
%
The result shows that non-blocking has significantly improved the latency of 
PUT communication. 
Non-blocking PUT is 4.63 times faster than blocking PUT on average from 8B to 8kB. 
Compared to the original PUT, it performs 8 times the communication in just 
2.11 times longer on average from 8B to 8kB.
%
In MPI eager protocol, non-blocking has no effect for latency hiding.
As the result, 8-variable non-blocking PUT had lower or almost the same 
latency than blocking and non-blocking MPI message passing.
The ratio is up to 2.17 times at 8kB comparing to 8-variable blocking MPI.

\begin{figure}
  \begin{center}
    %-- 8var-pipo-latency.pdf
    %\mbox{\includegraphics[trim=20mm 52mm 5mm 65mm,scale=0.45,clip]{graphs/8var-latency.pdf}}
    \mbox{\includegraphics[scale=0.45]{graphs/8var-latency-2.pdf}}
    \caption{8-variable ping-pong latency on PRIMEHPC FX100}\label{fig:8var-pingpong}
   \end{center}
\end{figure}
    

%\begin{figure}
%  \begin{center}
%    %-- 8var-pipo-bw.pdf
%    \mbox{\includegraphics[trim=40mm 180mm 43mm 0mm, scale=0.6,clip]{figs/8var-pipo-bw.pdf}}\\
%    (a) Bandwidth of blocking and non-blocking communications\\
%    %-- 8var-pipo-latency.pdf
%    \mbox{\includegraphics[trim=40mm 155mm 40mm 0mm, scale=0.6,clip]{figs/8var-pipo-latency.pdf}}\\
%    (b) Latency of blocking and non-blocking communications
%    \caption{8-variable ping-pong on PRIMEHPC FX100}\label{fig:8var-pingpong}
%   \end{center}
%\end{figure}



%===========================================================
\subsection{Himeno Benchmark}
%===========================================================


説明はどこかにある。\fig{himeno-graph}

%-- himeno-graph.pdf
\begin{figure}[p]
  \begin{center}
  % trimはleft bottom right topの順
    \mbox{\includegraphics[trim=37mm 34mm 37mm 4mm, scale=0.8,clip]{figs/himeno-graph-r2.pdf}}
    \caption{himeno-graph-r2.pdf}\label{fig:himeno-graph}
  \end{center}
\end{figure}


マシン名要確認。ころころ変えていないか。


% %-- 3cell-y.pdf
% %-- 3cell-z.pdf
% \begin{figure}[tbh]
%   \begin{center}
%   % trimはleft bottom right topの順
%   \fbox{\includegraphics[trim=98mm 235mm 98mm 0mm, scale=0.8,clip]{figs/3cell-y.pdf}}  \\
%   \fbox{\includegraphics[trim=85mm 261mm 85mm 0mm, scale=0.8,clip]{figs/3cell-z.pdf}}  \\
%   \fbox{\includegraphics[trim=82mm 230mm 84mm 0mm, scale=0.8,clip]{figs/9cell-yz.pdf}}
%   \caption{3cell-y.pdf, 3cell-z.pdf, 9cell-yz.pdf}\label{fig:cell}
%   \end{center}
% \end{figure}


%-- fx100-pipo.pdf
%    \fbox{\includegraphics[trim=4mm 15mm 4mm 3mm, scale=0.9,clip]{figs/fx100-pipo.pdf}}

%himeno.pdf
%latency-16var.pdf
%layer.pdf

%register-CA-tmp.pdf
%register-RA-CA-tmp.pdf
%register-RA-tmp.pdf
%softstack.pdf
%translator-tmp.pdf
